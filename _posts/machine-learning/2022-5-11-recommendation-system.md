---


layout: post
title: 推荐系统
---

## 推荐系统[[^1]]
* **ALS**: 矩阵分解算法，$Q=LR$,交替最小二乘。通过分别固定左右矩阵，依次更新。通过$L=QR^{-1}$，求得另一个矩阵。矩阵通过随机初始化，然后更新到收敛为止。

* **weighted-ALS**: 从评分预测问题转化为点击预测，其中浏览越多的权重越高。其中$C$为点击次数，$\alpha$一般为40。
  
  $$
  \begin{equation}
  min \sum c_{ui}(r_{ui}-q_u p_i)^2 + \lambda(...)
  \end{equation}
  $$

  $$
  \begin{equation}
  c_{ui} = 1+ \alpha C
  \end{equation}
  $$
  * 负样本采样一般推荐使用热门物品，随机的不是很靠谱。

* **BPR**: pair-wise, 评价指标使用AUC较为合适。不适合预测评分，适合预测行为。
  $$
	\begin{align}
    X_{u1,2} &= X_{u1} - X_{u2} \\
    p(1 \gt_u 2 ) &= \frac{1}{1+e^{-X_{u1,2}}}
  \end{align}
  $$

* **GDBT+LR**: 先训练GDBT，生成N棵树。来了新样本之后，走过所有的树，将访问到的叶子结点的值设为1，未访问到的设置为0。这样生成的one－hot特征，再丢到逻辑回归里做预测。
* **FM**: 就是加入了特征二阶组合的逻辑回归。为什么要二阶组合:例如年龄三十岁的男的对预测很重要，那么，做二阶组合就能提升效果。不做二阶组合达不到这个效果。而直接做二阶组合的话，参数过多，所以引入了参数对应的隐向量。
    * FM模型如果仅用用户ID和电影ID的话，那么就是带偏置SVD。
    * 如果加上历史观看的电影，那就是SVD＋＋
    * 加上时间信息就是time－SVD。
    * 所以FM可以在最后做模型融合。

* **FFM**：多加了多个隐向量，向量相乘时候选用另一个向量所在领域的向量。

* **wide&deep**: wide 一般是指以前做推荐一般都是特征工程＋逻辑回归。这样的好处是效果挺好，并且工程师可以并行工作，推荐的可解释性较强。但是深度学习出来之后，就希望引入deep的特征自动学习的能力。
  * 其中最后一层还是逻辑回归，deep的最后一层隐藏层和wide提取到的特征一起输入逻辑回归。
  * 其中数据要进行归一化（要变为正态分布，进行分桶处理）。
  * **优化**：Google的Wide&Deep模型中，要使用带L1正则化项的FTRL作为wide部分的优化方法，而使用AdaGrad作为deep部分的优化方法
    * L1 FTRL会让Wide部分的大部分权重都为0，我们准备特征的时候就不用准备那么多0权重的特征了，这大大压缩了模型权重，也压缩了特征向量的维度。

* Exploration and Exploitation: MAB 多臂老虎机。机会给确定好的选项和不确定的选项。评估指标：累积遗憾
  * 汤普森采样算法：根据beta分布来进行选取
  * UCB算法：根据进评分公式来选取
  * Epsilon 贪婪算法：$\epsilon$的概率随机选择一个选项，$1-\epsilon$的概率选择平均收益最高的。

  * (ridge 回归就是在矩阵对角线加上$I$，使得矩阵不那么病态？)
  * Lin－UCB: 给每个臂加上了特征。
  * COFIBA: 给Bandit算法加上了协同过滤。？（看不懂）

* **2Vec**
  * **doc2vec**: 在预测中间词的时候，附带上了段落id，所以在学习过程中能对段落id对应的embedding进行更新。一个段落有多少个滑动窗口就能更新几次。 
    * 能用来学习用户的embedding

* 常见算法：
  * **DeepFM**: 将最后wide+deep的输入换成FM模型。？？？
  * **FNN**: 使用提前训练好的FM对应的嵌入，而DeepFM是联合训练，并且没有wide ？？？
  * **NFM**： 两两逐元素相乘后求和？
  * **PNN**: 池化层换成向量积+FM？？？？？？
  * **DCN**：Cross Network + DNN。考虑数值特征，会将其拼接一起。
    $$
    X_{L+1} = X_0 * X_L^T * W_L + b_L + X_L
    $$ 

* **排行榜算法**：可以解决冷启动问题，老用户兴趣发现，推荐系统兜底算法。主要是得考虑时间因素，使得排行榜能够不断更新。
  * 一般就是 $\frac{投票数}{时间^\alpha}$ 或者 $\frac{投票数}{e^{时间}}$ 加上几个参数罢了。

* 重复检测：
  * 布隆过滤器：多个hash函数，将向量对应位置置1。（所以有将不存在的元素判断为存在的风险）
  * simhash：文本hash
  * 


* 构架：
  * 聚合信息流
    * 内容采集
    * 离线计算：一般是做用户画像，训练模型，也有少部分就输出推荐了。一般用hadoop做数据源。
    * 实时计算：在线排序召回 
    * 日志与监控：
  * 社交信息流：
    * 动态分发：一般活跃用户用推，不活跃的用拉。信息流存储可以用redis，推送则用Celery。消息队列：kafka
      * 推：
      * 拉：
    * 动态排序：得用RPC，例如Tensor Serving。
  * netflix：
    * 离线层
    * 实时层
    * 近线层：流计算：Strom， Spark Streaming， Flink

* 数据采集：
  * 日志系统：加埋点，前端后端，无埋点。

* 实时推荐：（难度依次增加）
  * 实时给出推荐结果
  * 实时特征更新
  * 实时模型更新 

* 流计算（storm）：
  * 组件
    * spout
    * Bolt
    * Tuple
    * Topology
  * 作用：
    * 清晰数据
    * 合并历史行为
    * 更新用户相似度
    * 在线更新机器学习模型
    * 更新推荐结果

* AB实验：
  * 需要分层，重叠，从而能同时进行多组实验。
  * 重叠实验
    * 来自上一层的流量需要合并后均匀分配到下一层，使得上一层的划分对下一层没有影响。
    * 每一层分桶时，散列函数需要加上层的ID，使得层和层分桶时独立。
    * 取模要一致，使用户体验一致

* 信息流api需要实现幂等，RESTFul API的一个要求，防止请求超时重新请求的时候，给出的推荐结果不一样了。

* 测试：
  * 软件测试
  * 离线模拟测试
  * 在线对照实验
  * 人工回访校验

* 指标：
  * 个性化程度：增加的物品或用户能否带来等比例的连接增加。或是对比不同用户推荐结果的相似度。
  * 基尼系数: 衡量马太效应，流量是不是都倾斜给头部item了
  * 多样性：类别分布是不是均衡啊

* 系统安全：
  * 攻击：水军，先得选目标用户，打相似评分，然后扶持对应的物品或者打压物品。还得随机打分以掩盖行为
  * 防护：防止注册，发现虚假评价，降低权重。

## 参考文献

[^1]: 推荐系统.陈开江.

