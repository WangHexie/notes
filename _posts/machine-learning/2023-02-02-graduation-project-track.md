---
layout: post
title: 毕设进度跟踪
---

## 方向一
* [ ] 数据比例
* [ ] 固定随机数种子
 

## 方向二
* [x] GNNbenchmark 论文阅读
  * [x] mnist数据集是怎么制作的？:super pixel
  * [x] GNN是什么结构？（调优模型到sota）: graphsage 非常不错
* [x] 调优并测试所有的算法
  * [x] NAD搞好了
  * [x] finetuning 也搞好了
  * [x] ABL基本也好了，但是ABL有一个问题就是选的数据不能太多，不然最后一个环节有很多干净样本结果会很难看。
* [x] 选一个算法作为基础，然后叠加另一个算法:我选好了
* [ ] 思路
  * [ ] 复制几层，其他的重新训练
  * [ ] 全部重新初始化后蒸馏
  * [x] 干净的数据集数量很重要，所以使用loss将数据集用ABL过滤出来之后重新训练（**In progeress**）
    * [ ] 我选出来了，但是选出来之后的比例还是的继续减少的
    * [ ] 然后作为poison的data的一个数据必须要数量再减少，使其可信度增加
    * [ ] 然后引入smooth softmax  
    * [x] 检查随机数种子固定后选取的数字是否一致
  * [x] 可视化一下，看看loss的变化过程，以及poisoned data 的loss 分布情况 
    * [x] ABL也需要可视化
    * [x] 并且对ABL超参数对结果的影响进行可视化
    * [x] 完全可以使用kmeans将两者分开:实验表明并不行，需要使用其他方法
      * [x] 测试其他方法或者直接自己进行写
      * [x] 使用非监督的指标进行评估选取训练到什么时候的数据：目前的想法使类内距离除以类间距离，或者呢，直接就用类间最小距离得了，
  * [ ] 增加个我们自己的方法
