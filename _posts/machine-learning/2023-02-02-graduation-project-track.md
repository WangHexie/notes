---
layout: post
title: 毕设进度跟踪
---

## 方向一

* [x] 数据比例: 原作者的代码就是狗屎，改任何代码都是在屎山上打滚。我真的服了，本来两行代码完事的东西，我得全部代码看一遍，看看有什么地方耦合的。真的狗屎，作者但凡学点软件工程的课程也不会写出这么垃圾的代码出来。清华的老哥写的比这好多了，真的什么狗屎东西，结果都没法复现全是bug的狗屎。不要脸的狗东西，还开源出来，害人害己。
  * 真的傻逼代码，根本解耦不出来，早知道我就全部重写了。类都不会用的废物，module当类调。数据集划分这么一个简单的function非得嵌入到数据集读取里才能实现。
  * 需要测试，仅仅改了adv_train那里
  * [x] 测好了，所有实验需要重新跑过并重新整理实验数据:目前实验有点问题，估计是保存参数的时候不一致，现在正在重新跑。
  * [ ] 为什么数据越多效果越差呢，是不是过拟合了呢
    * [ ] 触发器相似度
* [x] 固定随机数种子

## 方向二

* [x] GNNbenchmark 论文阅读
  * [x] mnist数据集是怎么制作的？:super pixel
  * [x] GNN是什么结构？（调优模型到sota）: graphsage 非常不错
* [x] 调优并测试所有的算法
  * [x] NAD搞好了
  * [x] finetuning 也搞好了
  * [x] ABL基本也好了，但是ABL有一个问题就是选的数据不能太多，不然最后一个环节有很多干净样本结果会很难看。
* [x] 选一个算法作为基础，然后叠加另一个算法:我选好了
* [ ] 思路
  * [ ] 复制几层，其他的重新训练
  * [ ] 全部重新初始化后蒸馏
  * [x] 干净的数据集数量很重要，所以使用loss将数据集用ABL过滤出来之后重新训练（**In progeress**）
    * [ ] 我选出来了，但是选出来之后的比例还是的继续减少的
    * [ ] 然后作为poison的data的一个数据必须要数量再减少，使其可信度增加
    * [ ] 然后引入smooth softmax  
    * [x] 检查随机数种子固定后选取的数字是否一致
  * [x] 可视化一下，看看loss的变化过程，以及poisoned data 的loss 分布情况 
    * [x] ABL也需要可视化
    * [x] 并且对ABL超参数对结果的影响进行可视化
    * [x] 完全可以使用kmeans将两者分开:实验表明并不行，需要使用其他方法
      * [x] 测试其他方法或者直接自己进行写
      * [x] 使用非监督的指标进行评估选取训练到什么时候的数据：目前的想法使类内距离除以类间距离，或者呢，直接就用类间最小距离得了，
  * [x] 增加个我们自己的方法:
    * [ ] 全量实验结果跑出来了，但是效果不好，训练不稳定，现在计划看看，
      * [x] 到底筛选出来的准确率多少：abl那个准确率不好的原因知道，分离异常数据的准确率不行，0.05准确率还没0.01好
      * [x] 训练后重新初始化模型：效果非常好，基本恢复了
      * [x] 更换数据集
      * [x] 整理实验数据
        * [ ] 根据实验数据对模型进行分析:现在目前的分析结果就是还是badnet攻击没有太成功，拟合基本失败了，导致脏数据区分不出来。
      * [ ] 加上smooth softmax
      * [ ] 加上NAD
      * [ ] 总结实验，文档化
  * [ ] 实验分析：
    * [ ] 图神经网络的拟合能力对算法的影响
    * [ ] 攻击成功率对算法的影响

## 最终的毕设

* [ ] 开始参考学长的论文写综述什么的了
* [ ] 写一个框架出来：
  * [ ] 绪论：10页
  * [ ] 相关技术介绍： 12页
  * [ ] 算法1：13页
  * [ ] 算法2：21页
  * [ ] 系统实现：6页
  * [ ] 总结与展望：2页

