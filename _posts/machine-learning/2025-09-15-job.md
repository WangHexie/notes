---
layout: post
title: 面试
---

* 得物一:
    * 线上线下不一致（指的是指标不一致，离线涨线下不涨）：
        * 训练时候：指标根本没有对齐线上，例如离线指标看的auc，实际上GAUC涨了才有收益；训练目标也和线上不一致，线上评估一个月的，线下转化标签只有24h的。长期转化看不到；训练标签就有问题，关联上或者标签是有问题的等的。
        * ab阶段：流量分配不均匀，aa就有问题；其他ab实验叠加导致有问题。
        * 推理阶段：
            1. 评估样本不一样，例如离线只评估曝光样本，线上可能会评估其他样本，导致其他样本曝光，以及数据采样策略的问题 离线训练样本的分布和线上不一样，线上可能新用户占比比较高
            1. 特征不一样：训练时候能拿到线上拿不到的标签和特征；工程漏填错填特征了
            1. 模型不一样：线上加载的模型有问题，Embedding没有加载上；dropout等设置有问题；batchnorm没有加载上
            1. 下游问题：q打分分布不一样了，导致后续重排逻辑出问题了
            1. 其他线上问题：耗时涨了很多，导致收益没了。
    * dead relu的原因并且如何恢复？如何避免？
        * 成因：
          * 学习率太高，一次更新就将b/w推的太负了
          * 初始化有问题：
            * relu会将方差减半，导致到后面方差越来越小，会被b主导
            * 方差过大：会导致输出过大，后续梯度很大，直接使b一下更新到很负的负数
            * 解决：初始化需要将var乘以2
          * 不小心对b也进行了权重衰减。以及b为0初始化
            * 解决：初始化大一点
          * 输入偏移了，导致在负半区
          * 深网络导致最后能是上游更新的通路很少了，每次有一半都没法更新的；并且会使层间的输出偏移，之后变得更快负。
            * resnet并且batchnorm
          * 并且类别不均衡
        * 拯救：
          * 立马降低学习率
          * 立马换损失函数
          * 重新初始化


